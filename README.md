---
title: Fastener Agent
emoji: ðŸ¤–
colorFrom: blue
colorTo: green
sdk: gradio
app_file: app.py
pinned: false
---

# Documentation for RAG System with Image Processing

## Overview
This system integrates **Retrieval-Augmented Generation (RAG)** with **image classification** to help users identify geometric objects and retrieve relevant fastener and manufacturing recommendations. The system allows users to upload an image, analyzes its features, and retrieves relevant information using a chatbot interface.

## System Components

### 1. Image Processing and Classification
The first step is understanding the geometry of an uploaded image. This is crucial because different geometrical shapes require different fasteners. We use **ResNet50** from the `torchvision.models` library, a well-known deep learning model for image classification, to extract meaningful features from images. These extracted features (embeddings) represent the geometry in a way that makes comparison possible.

To recognize an image, we first create embeddings for a set of reference images (e.g., flat, cylindrical, and complex shapes) using **ResNet50** and **Torch**. These embeddings are numerical representations of the images, capturing their key features. We store them as vectors using `NumPy` for efficient retrieval.

When a user uploads an image, its embedding is generated using the same model and compared with the reference embeddings using **cosine similarity** from the `sklearn.metrics.pairwise` module. Cosine similarity measures the angle between two vectors: a similarity score close to 1 means the uploaded image is very similar to a reference shape, while a lower score means they are different. This helps in identifying the correct geometric classification for the uploaded image.

### 2. Document Processing & Retrieval
Once the image classification determines the geometry, we need to provide relevant information about suitable fasteners. The system processes **.docx documents** containing manufacturing guidelines and fastener recommendations. Since these documents contain a mix of text and tables, we extract text using `python-docx` and structure it into smaller chunks (1500 characters each) for easier retrieval.

To enable fast search, we convert the text chunks into embeddings using `sentence-transformers` and store them in **FAISS (Facebook AI Similarity Search)**, a high-performance vector database. When a user asks a question, the system generates a query embedding using `sentence-transformers` and retrieves the most relevant text chunks using **cosine similarity** in FAISS. Only chunks with a similarity score above 0.5 are considered relevant.

### 3. Query Validation & Response Generation
Retrieving relevant text chunks is not enough; we need to ensure they actually answer the user's query. To do this, we use an **LLM (Mistral-7B-Instruct-v0.2)** via `transformers` to generate a final response based on the retrieved documents. The query embedding is passed through **retrieval validation**, where we check if the retrieved documents contain semantically relevant information using `spacy` and `nltk`. If they arenâ€™t relevant, we discard them and provide a fallback response.

The **LLM response generation** takes both the user query and the retrieved documents as context. This ensures that the answer is well-informed and precise, rather than relying solely on generative AI output.

### 4. Chatbot & User Interaction
Users interact with the system through a **Gradio-powered chatbot** (`gradio.Blocks`). The chatbot allows users to:
1. Upload an image to detect its geometry.
2. Ask questions about fasteners and manufacturing based on the detected geometry.
3. Receive responses generated by the **RAG model**, which combines retrieved documents and LLM-generated answers.

The system dynamically updates responses based on user queries, ensuring accurate and informative answers. The chatbot interface is built using **Gradio**, which allows easy integration with different models and seamless user interactions.

### 5. Running the System
To start the system, run:
```python
if __name__ == "__main__":
    demo()
```
This launches the **Gradio interface**, where users can upload images and interact with the chatbot in real time.

---
### Summary
- **Image Processing**: Uses `torchvision.models` (ResNet50) to classify geometry and compare embeddings using `sklearn` cosine similarity.
- **RAG Retrieval**: Uses `sentence-transformers` to convert text into embeddings and FAISS for fast vector retrieval.
- **Query Validation**: Ensures high-quality responses by filtering irrelevant document chunks before response generation using `spacy` and `nltk`.
- **LLM Response**: Uses `transformers` to generate responses from `Mistral-7B-Instruct-v0.2`.
- **User Interaction**: Provides an interactive chatbot interface using `Gradio` for easy image uploads and queries.

This documentation explains how the system works step by step, ensuring an intuitive and efficient user experience.
